![Drug Discovery Image](https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1464187604.jpg)

# Desafio Final da Terceira Imers√£o Dados da Alura
---

Ol√°! Bem vindo ao meu reposit√≥rio relativo a Terceira imers√£o de dados da Alura! Aqui, na pasta **notebooks**, estar√° uma analise feita em cima dos dados com um modelo para prever qual a√ß√£o dos mecanismos de a√ß√£o foi utilizada! Abaixo detalherei melhor qual o escopo do projeto, quais dados ser√£o utilizados e como eu pretendo achar um modelo para prever tal situa√ß√£o.


## Os dados
---

Nesse projeto, est√£o sendo utilizados dados fornecidos em uma competi√ß√£o no [kaggle](https://www.kaggle.com/c/lish-moa) pelo [Laboratory innovation science de Harvard](https://lish.harvard.edu/) relativo a *drug discovery*, que √© a descoberta de novos medicamentos atrav√©s de dados do efeito de compostos sobre determinados genes e grupo celulares. 

## O Objetivo
---

Ap√≥s a aula 04 da imers√£o de dados, me surgiu o questionamento se seria poss√≠vel predizer a a√ß√£o dos Mecanismos de a√ß√£o atrav√©s da altera√ß√£o nos genes e nos grupos celulares. Por isso, essa ser√° o foco do meu trabalho final! Tentar prever essa a√ß√£o üòä

## Como ser√° feito
---

Para obter isso, primeiro de tudo ser√° feito uma analise explorat√≥ria e contextualiza√ß√£o dos dados. Feito isso, ser√£o feitas algumas transforma√ß√µes, com o objetivo de deixar nossos dados melhores aptos para os nossos modelos de machine learning propriamente dito. O problema foi descrito de forma que se encaixa em problemas de classifica√ß√£o, portanto, ser√£o tentadas 3 abordagens: *MultiLayer Perceptron* - MLP usando Scikit-learn, AutoML (Auto-sklearn) e *Gradient boosted trees* (XGBoost). Justificando as escolhas: redes neurais em geral √© uma abordagem bastante comum em problemas de classifica√ß√£o multilabel, ent√£o parece um bom ponto inicial. J√° AutoML em geral, √© uma √°rea bastante em alta devido a sua simplicidade e facilita√ß√£o do trabalho dos Cientista de dados em geral. Por fim, o XGBoost √© um dos modelos que mais aparecem nas melhores solu√ß√µes de competi√ß√µes de problemas de classifica√ß√£o em geral, sendo, no meu caso pelo menos, o primeiro modelo a ser testado.

## Resultados
---

Ap√≥s aplica√ß√£o dos modelos foram obtidos os seguintes resultados de acur√°cia:

*MultiLayer Perceptrons - MLP* (Rede neural) -> 41,4 %

*Auto-ML* (Auto-sklearn)                     -> 39.0 %

*XGBoost*                                    -> 49.5 % 

## Conclus√µes
---

Atrav√©s de melhores estudos e aperfei√ßoamento dos parametros, √© poss√≠vel encontrar modelos mais precisos do que os determinados acima. Contudo, essa r√°pida explora√ß√£o dos modelos de aprendizado de m√°quina, mostrou que XGBoost talvez sejam o melhor caminho para a solu√ß√£o desse problema.


[Colab do Notebook](https://drive.google.com/file/d/1UCy_yNMwiuAapbH_XPlc2Xi3x7SRPu7o/view?usp=sharing)
